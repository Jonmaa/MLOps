apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: mnist-classification-
spec:
  entrypoint: mnist-pipeline
  volumes:
  - name: shared-data
    emptyDir: {}

  templates:
  - name: mnist-pipeline
    dag:
      tasks:
      - name: train-model
        template: train-model
      - name: evaluate-model
        template: evaluate-model
        dependencies: [train-model]
        arguments:
          artifacts:
          - name: trained-model
            from: "{{tasks.train-model.outputs.artifacts.trained-model}}"

  - name: train-model
    container:
      image: pytorch/pytorch:latest
      command: ["sh", "-c"]
      args:
      - |
        # Instalar scikit-learn primero
        pip install scikit-learn --quiet && \
        
        # Crear archivo con definición de clase y entrenamiento
        cat > /mnt/data/train.py << 'EOF'
        import torch
        import torch.nn as nn
        import torch.optim as optim
        from torchvision import datasets, transforms
        import os

        class DeepNN(nn.Module):
            def __init__(self):
                super(DeepNN, self).__init__()
                self.fc1 = nn.Linear(28*28, 512)
                self.fc2 = nn.Linear(512, 256)
                self.fc3 = nn.Linear(256, 128)
                self.fc4 = nn.Linear(128, 64)
                self.fc5 = nn.Linear(64, 10)
                self.dropout = nn.Dropout(p=0.3)

            def forward(self, x):
                x = x.view(-1, 28*28)
                x = torch.relu(self.fc1(x)); x = self.dropout(x)
                x = torch.relu(self.fc2(x)); x = self.dropout(x)
                x = torch.relu(self.fc3(x)); x = self.dropout(x)
                x = torch.relu(self.fc4(x)); x = self.dropout(x)
                return self.fc5(x)

        def train_and_save():
            transform = transforms.Compose([transforms.ToTensor()])
            train_ds = datasets.MNIST(root='/tmp/mnist_data', train=True,
                                    transform=transform, download=True)
            train_loader = torch.utils.data.DataLoader(train_ds, batch_size=64,
                                                     shuffle=True)

            model = DeepNN()
            optimizer = optim.Adam(model.parameters(), lr=0.001)
            criterion = nn.CrossEntropyLoss()

            for epoch in range(10):
                total_loss = 0.0
                for images, labels in train_loader:
                    optimizer.zero_grad()
                    outputs = model(images)
                    loss = criterion(outputs, labels)
                    loss.backward()
                    optimizer.step()
                    total_loss += loss.item()
                print(f'Epoch {epoch+1}/10, loss={total_loss/len(train_loader):.4f}')

            os.makedirs('/mnt/data', exist_ok=True)
            model_path = '/mnt/data/mnist_model.pth'
            torch.save({
                'model_state_dict': model.state_dict(),
                'model_class': 'DeepNN'
            }, model_path)
            print(f'Modelo guardado en {model_path}')
        
        if __name__ == '__main__':
            train_and_save()
        EOF

        # Ejecutar entrenamiento
        python /mnt/data/train.py
      volumeMounts:
      - name: shared-data
        mountPath: /mnt/data
    outputs:
      artifacts:
      - name: trained-model
        path: /mnt/data/mnist_model.pth

  - name: evaluate-model
    container:
      image: pytorch/pytorch:latest
      command: ["sh", "-c"]
      args:
      - |
        # Instalar scikit-learn primero
        pip install scikit-learn --quiet && \
        
        # Crear archivo con definición de clase y evaluación
        cat > /mnt/data/evaluate.py << 'EOF'
        import torch
        from torchvision import datasets, transforms
        from sklearn.metrics import accuracy_score, classification_report

        class DeepNN(torch.nn.Module):
            def __init__(self):
                super(DeepNN, self).__init__()
                self.fc1 = torch.nn.Linear(28*28, 512)
                self.fc2 = torch.nn.Linear(512, 256)
                self.fc3 = torch.nn.Linear(256, 128)
                self.fc4 = torch.nn.Linear(128, 64)
                self.fc5 = torch.nn.Linear(64, 10)
                self.dropout = torch.nn.Dropout(p=0.3)

            def forward(self, x):
                x = x.view(-1, 28*28)
                x = torch.relu(self.fc1(x)); x = self.dropout(x)
                x = torch.relu(self.fc2(x)); x = self.dropout(x)
                x = torch.relu(self.fc3(x)); x = self.dropout(x)
                x = torch.relu(self.fc4(x)); x = self.dropout(x)
                return self.fc5(x)

        def evaluate():
            # Cargar modelo
            checkpoint = torch.load('/mnt/data/mnist_model.pth')
            model = DeepNN()
            model.load_state_dict(checkpoint['model_state_dict'])
            model.eval()

            # Evaluación
            transform = transforms.Compose([transforms.ToTensor()])
            test_ds = datasets.MNIST(root='/tmp/mnist_data', train=False,
                                   transform=transform, download=True)
            test_loader = torch.utils.data.DataLoader(test_ds, batch_size=64,
                                                    shuffle=False)

            all_preds, all_labels = [], []
            with torch.no_grad():
                for images, labels in test_loader:
                    outputs = model(images)
                    _, preds = torch.max(outputs, 1)
                    all_preds.extend(preds.tolist())
                    all_labels.extend(labels.tolist())

            acc = accuracy_score(all_labels, all_preds)
            print(f'Accuracy en test: {acc*100:.2f}%')
            print(classification_report(all_labels, all_preds,
                                      target_names=[str(i) for i in range(10)]))
        
        if __name__ == '__main__':
            evaluate()
        EOF

        # Ejecutar evaluación
        python /mnt/data/evaluate.py
      volumeMounts:
      - name: shared-data
        mountPath: /mnt/data
    inputs:
      artifacts:
      - name: trained-model
        path: /mnt/data/mnist_model.pth
